{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     palavras                                            sentido\n",
      "1      riacho              rio pequeno de dois metros de largura\n",
      "2       açude             rio pequeno de dois metros de largura'\n",
      "3       lagoa              rio pequeno de dois metros de largura\n",
      "4    barreiro              rio pequeno de dois metros de largura\n",
      "5         rio              rio pequeno de dois metros de largura\n",
      "..        ...                                                ...\n",
      "258     torno  peça usada para modelagem de figuras ou panela...\n",
      "259     fôrma  peça usada para modelagem de figuras ou panela...\n",
      "260    panela  peça usada para modelagem de figuras ou panela...\n",
      "261   máquina  peça usada para modelagem de figuras ou panela...\n",
      "262     bacia  peça usada para modelagem de figuras ou panela...\n",
      "\n",
      "[262 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "cabecalho = ['palavras', 'sentido']\n",
    "#Base de dados de palavras polissemicas\n",
    "base = pd.read_csv('./palavras_atlas.csv', sep=';', names=cabecalho, encoding='utf-8')\n",
    "print(base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-6efa9b1be463>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mfrasescomstemming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfazstemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-6efa9b1be463>\u001b[0m in \u001b[0;36mfazstemmer\u001b[0;34m(texto)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstemmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRSLPStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfrasessstemming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtexto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalavras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentido\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexto\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         comstemming = [str(stemmer.stem(p))\n\u001b[1;32m      9\u001b[0m                        for p in palavras.split() if p not in stopwordsnltk]\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "stopwordsnltk = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "\n",
    "def fazstemmer(texto):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    frasessstemming = []\n",
    "    for (texto.palavras, texto.sentido) in texto:\n",
    "        comstemming = [str(stemmer.stem(p))\n",
    "                       for p in palavras.split() if p not in stopwordsnltk]\n",
    "        frasessstemming.append((comstemming, texto.sentido))\n",
    "    return frasessstemming\n",
    "\n",
    "\n",
    "frasescomstemming = fazstemmer(base)\n",
    "\n",
    "\n",
    "def buscapalavras(frases):\n",
    "    todaspalavras = []\n",
    "    for (palavras, sentido) in frases:\n",
    "        todaspalavras.extend(palavras)\n",
    "    return todaspalavras\n",
    "\n",
    "\n",
    "palavras = buscapalavras(frasescomstemming)\n",
    "\n",
    "\n",
    "def buscafrequencia(palavras):\n",
    "    palavras = nltk.FreqDist(palavras)\n",
    "    return palavras\n",
    "\n",
    "\n",
    "frequenciatreinamento = buscafrequencia(palavras)\n",
    "\n",
    "\n",
    "def busca_palavrasunicas(frequencia):\n",
    "    freq = frequencia.keys()\n",
    "    return freq\n",
    "\n",
    "\n",
    "palavrasunicas = busca_palavrasunicas(frequenciatreinamento)\n",
    "\n",
    "\n",
    "def extraipalavras(documento):\n",
    "    doc = set(documento)\n",
    "    caracteristicas = {}\n",
    "    for palavras in palavrasunicas:\n",
    "        caracteristicas['%s' % palavras] = (palavras in doc)\n",
    "    return caracteristicas\n",
    "\n",
    "\n",
    "basecompleta = nltk.classify.apply_features(extraipalavras, frasescomstemming)\n",
    "\n",
    "classificador = nltk.NaiveBayesClassifier.train(basecompleta)\n",
    "\n",
    "def extrai_palavras(documento):\n",
    "    doc = set(documento)\n",
    "    caracteristicas = {}\n",
    "    for palavras in palavrasunicas:\n",
    "        caracteristicas['%s' % palavras] = (palavras in doc)\n",
    "    return caracteristicas\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extrai_palavras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-821996f88e77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtestestem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomstem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnova_frase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextrai_palavras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestestem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdistribuicao\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassificador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnova_frase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'extrai_palavras' is not defined"
     ]
    }
   ],
   "source": [
    "teste = 'Luna tirou o aplicativo do banco do meu celular, oooh garotinha filho'\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, (distribuicao.prob(classe)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "banco_onde_saca_dinheiro: 0.006956\n",
      "banco_de_dados: 0.359913\n",
      "banco_de_sangue: 0.002282\n",
      "banco_de_sentar: 0.108193\n",
      "bala_de_arma: 0.000025\n",
      "bala_de_doce: 99.522631\n"
     ]
    }
   ],
   "source": [
    "teste = 'e se eu fizesse um \"banco de dados\" com muitas Fanart de #SeikenDensetsu? como seriá?'\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, (distribuicao.prob(classe)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "banco_onde_saca_dinheiro: 0.000050\n",
      "banco_de_dados: 0.000006\n",
      "banco_de_sangue: 0.000000\n",
      "banco_de_sentar: 0.000096\n",
      "bala_de_arma: 0.002247\n",
      "bala_de_doce: 99.997601\n"
     ]
    }
   ],
   "source": [
    "teste = 'vi uma receita de bala de goma muito da hora <3'\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, (distribuicao.prob(classe)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "banco_onde_saca_dinheiro: 1.194069\n",
      "banco_de_dados: 68.839554\n",
      "banco_de_sangue: 0.004611\n",
      "banco_de_sentar: 26.672324\n",
      "bala_de_arma: 0.000032\n",
      "bala_de_doce: 3.289409\n"
     ]
    }
   ],
   "source": [
    "teste = 'Governo quer reunir em banco de dados informações genéticas de 100 mil brasileiros'\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, (distribuicao.prob(classe)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "banco_onde_saca_dinheiro: 0.448127\n",
      "banco_de_dados: 1.088993\n",
      "banco_de_sangue: 83.535651\n",
      "banco_de_sentar: 11.611918\n",
      "bala_de_arma: 0.000031\n",
      "bala_de_doce: 3.315280\n"
     ]
    }
   ],
   "source": [
    "teste = 'Banco de sangue da BP recebe acreditação internacional '\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, (distribuicao.prob(classe)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "banco_onde_saca_dinheiro: 0.199404\n",
      "banco_de_dados: 0.064462\n",
      "banco_de_sangue: 0.000205\n",
      "banco_de_sentar: 0.110073\n",
      "bala_de_arma: 0.001042\n",
      "bala_de_doce: 99.624813\n"
     ]
    }
   ],
   "source": [
    "teste = 'Jovem é preso com colete à prova de balas, arma e munições, em Governador Valadares '\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, (distribuicao.prob(classe)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "banco_onde_saca_dinheiro: 0.000220\n",
      "banco_de_dados: 0.000262\n",
      "banco_de_sangue: 0.000001\n",
      "banco_de_sentar: 0.034608\n",
      "bala_de_arma: 0.033681\n",
      "bala_de_doce: 99.931229\n"
     ]
    }
   ],
   "source": [
    "teste = 'Fini lança sua primeira linha de balas veganas ‘Frutiê’'\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, (distribuicao.prob(classe)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "banco_onde_saca_dinheiro: 0.023452\n",
      "banco_de_dados: 0.096224\n",
      "banco_de_sangue: 0.002959\n",
      "banco_de_sentar: 99.663623\n",
      "bala_de_arma: 0.000002\n",
      "bala_de_doce: 0.213741\n"
     ]
    }
   ],
   "source": [
    "teste = 'A Fazenda: sentada violenta de Jojo Todynho faz banco quebrar durante atividade: “Puta que pariu!”'\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, (distribuicao.prob(classe)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "banco_onde_saca_dinheiro: 0.042105\n",
      "banco_de_dados: 0.548131\n",
      "banco_de_sangue: 0.023095\n",
      "banco_de_sentar: 98.419376\n",
      "bala_de_arma: 0.000009\n",
      "bala_de_doce: 0.967284\n"
     ]
    }
   ],
   "source": [
    "teste = 'CS:GO: Sharks dispensa supLex e coloca Luken no banco de reservas'\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, (distribuicao.prob(classe)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "banco_onde_saca_dinheiro: 0.038255\n",
      "banco_de_dados: 0.145111\n",
      "banco_de_sangue: 1.354899\n",
      "banco_de_sentar: 97.741509\n",
      "bala_de_arma: 0.000002\n",
      "bala_de_doce: 0.720225\n"
     ]
    }
   ],
   "source": [
    "teste = 'Jogador do Confiança passa mal no banco de reservas e sai de ambulância'\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, (distribuicao.prob(classe)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "banco_onde_saca_dinheiro: 0.000022\n",
      "banco_de_dados: 0.000007\n",
      "banco_de_sangue: 0.000000\n",
      "banco_de_sentar: 0.000358\n",
      "bala_de_arma: 0.005135\n",
      "bala_de_doce: 99.994477\n"
     ]
    }
   ],
   "source": [
    "teste = 'Adolescente ameaça mãe e só para com tiro de bala de borracha'\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, (distribuicao.prob(classe)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "banco_onde_saca_dinheiro: 28.450667\n",
      "banco_de_dados: 1.654181\n",
      "banco_de_sangue: 0.069851\n",
      "banco_de_sentar: 54.222083\n",
      "bala_de_arma: 0.000148\n",
      "bala_de_doce: 15.603069\n"
     ]
    }
   ],
   "source": [
    "teste = 'Banco Central registra recorde de remessas de dólares para Brasil'\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, (distribuicao.prob(classe)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "banco_onde_saca_dinheiro: 82.839362\n",
      "banco_de_dados: 3.257246\n",
      "banco_de_sangue: 0.270401\n",
      "banco_de_sentar: 8.079382\n",
      "bala_de_arma: 0.000006\n",
      "bala_de_doce: 5.553603\n"
     ]
    }
   ],
   "source": [
    "teste = 'Retirar dinheiro de bancos públicos não resolve dívida do país'\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, (distribuicao.prob(classe)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "banco_onde_saca_dinheiro: 0.000779\n",
      "banco_de_dados: 0.000279\n",
      "banco_de_sangue: 0.000003\n",
      "banco_de_sentar: 0.019941\n",
      "bala_de_arma: 0.035930\n",
      "bala_de_doce: 99.943067\n"
     ]
    }
   ],
   "source": [
    "teste = 'Marca espanhola de balas abre primeira franquia no RS'\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, (distribuicao.prob(classe)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "banco_onde_saca_dinheiro: 0.084970\n",
      "banco_de_dados: 1.143646\n",
      "banco_de_sangue: 87.068829\n",
      "banco_de_sentar: 9.618181\n",
      "bala_de_arma: 0.000019\n",
      "bala_de_doce: 2.084355\n"
     ]
    }
   ],
   "source": [
    "teste = 'Banco de Sangue Hemato muda de endereço e aumenta capacidade de atendimento'\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, (distribuicao.prob(classe)*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         |           b |\n",
      "                         |           a |\n",
      "                         |           n |\n",
      "                         |           c |\n",
      "                         |           o |\n",
      "                         |           _ |\n",
      "                         |           o |\n",
      "                         |           n |\n",
      "                         |           d |\n",
      "                         |       b b e |\n",
      "                         |     b a a _ |\n",
      "                         |     a n n s |\n",
      "                         | b b n c c a |\n",
      "                         | a a c o o c |\n",
      "                         | l l o _ _ a |\n",
      "                         | a a _ d d _ |\n",
      "                         | _ _ d e e d |\n",
      "                         | d d e _ _ i |\n",
      "                         | e e _ s s n |\n",
      "                         | _ _ d a e h |\n",
      "                         | a d a n n e |\n",
      "                         | r o d g t i |\n",
      "                         | m c o u a r |\n",
      "                         | a e s e r o |\n",
      "-------------------------+-------------+\n",
      "            bala_de_arma |<.>1 . . . . |\n",
      "            bala_de_doce | .<4>. . . . |\n",
      "          banco_de_dados | . 2<.>. . . |\n",
      "         banco_de_sangue | . . .<2>. . |\n",
      "         banco_de_sentar | . 1 . .<2>. |\n",
      "banco_onde_saca_dinheiro | . . . . 2<1>|\n",
      "-------------------------+-------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import ConfusionMatrix\n",
    "esperado = [\n",
    "\"banco_onde_saca_dinheiro\",\n",
    "\"banco_de_dados\",\n",
    "\"bala_de_doce\",\n",
    "\"banco_de_dados\",\n",
    "\"banco_de_sangue\",\n",
    "\"bala_de_doce\",\n",
    "\"bala_de_doce\",\n",
    "\"banco_de_sentar\",\n",
    "\"banco_de_sentar\",\n",
    "\"banco_de_sentar\",\n",
    "\"bala_de_arma\",\n",
    "\"banco_onde_saca_dinheiro\",\n",
    "\"banco_onde_saca_dinheiro\",\n",
    "\"bala_de_doce\",\n",
    "\"banco_de_sangue\"]\n",
    "\n",
    "previsto = [\n",
    "\"banco_de_sentar\",\n",
    "\"bala_de_doce\",\n",
    "\"bala_de_doce\",\n",
    "\"bala_de_doce\",\n",
    "\"banco_de_sangue\",\n",
    "\"bala_de_doce\",\n",
    "\"bala_de_doce\",\n",
    "\"banco_de_sentar\",\n",
    "\"bala_de_doce\",\n",
    "\"banco_de_sentar\",\n",
    "\"bala_de_doce\",\n",
    "\"banco_de_sentar\",\n",
    "\"banco_onde_saca_dinheiro\",\n",
    "\"bala_de_doce\",\n",
    "\"banco_de_sangue\"]\n",
    "\n",
    "matriz = ConfusionMatrix(esperado, previsto)\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "          banco_de_dados       0.00      0.00      0.00         1\n",
      "         banco_de_sangue       0.50      1.00      0.67         4\n",
      "         banco_de_sentar       0.00      0.00      0.00         2\n",
      "banco_onde_saca_dinheiro       1.00      1.00      1.00         2\n",
      "            bala_de_doce       0.50      0.67      0.57         3\n",
      "            bala_de_arma       1.00      0.33      0.50         3\n",
      "\n",
      "                accuracy                           0.60        15\n",
      "               macro avg       0.50      0.50      0.46        15\n",
      "            weighted avg       0.57      0.60      0.53        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matheus/snap/jupyter/common/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "target_names = ['banco_de_dados', 'banco_de_sangue', 'banco_de_sentar', 'banco_onde_saca_dinheiro', 'bala_de_doce', 'bala_de_arma']\n",
    "\n",
    "print(classification_report(esperado, previsto, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
